---
title: "Rosetta"
author: "M Schmettow"
date: "05/10/2022"
output: html_document
---

```{r message=FALSE, warning=FALSE}

library(tidyverse)
library(printr)
require(readxl)
require(jpeg)
require(ggimg)
```


## Reading single file data

We define two functions that read the stimuli information and the AOI coordinates from separate csv files. In all three languages, a type table can be defined, albeit with different means. These functions alter the table by renaming columns (File) and calculating new columns (ymin, xmax, ...).

### Tidyverse

```{r}
library(tidyverse)

stim_types <- cols(File = col_character(),
                            width = col_double(),
                            height = col_double(),
                            hum_like = col_double(),
                            hum_skull = col_logical(),
                            hum_eye = col_logical(),
                            Face = col_character())

stim_dir = "Stimuli"

stims <- 
  read_csv(file.path(stim_dir, "Stimuli.csv"), col_types = stim_types) |> 
  mutate(Path = str_c(stim_dir, File, sep = "")) |> 
  rename(Stim = File)

aoi_types <- cols(AOI = col_character(), Face = col_character(), 
                    x = col_double(), y = col_double(), 
                    w = col_double(), h = col_double())

aoi <-    
  read_csv("Stimuli/AOI.csv", col_types = aoi_types) %>% 
  mutate(xmin = x, 
         xmax = x + w,
         ymin = y - h,
         ymax = y) |>  ## reversing the y coordinates) %>%
  rename(x_aoi = x, y_aoi = y, w_aoi = w, h_aoi = h) |> 
  arrange(Face, AOI)

```



### Pandas

In Pandas, calculating new columns requires the use of lambdas (anonymous functions that inherit the context). This is so tedious, that I stop using Pandas as of now.

```{python eval = FALSE}
from pandas import read_csv
import os

stim_dir = os.path.dirname("Stimuli")

dtype = {
        'File': 'string',
        'width': 'int16',
        'height': 'int16',
        'hum_like': 'float32',
        'hum_skull': 'boolean',
        'hum_eyes': 'boolean',
        'Face': 'string'
    }
stims = read_csv(os.path.join(stim_dir, "Stimuli.csv"), dtype = dtype)\
          .apply(lambda row: os.path.join(stim_dir, row["File"]),  axis = 1)


stims = read_yeta1_stim()
stims.sample(10)
```



### Polars

With Polars, one uses the `with_columns`method to calculate new columns as expressions. This seems better than Pandas, but is not remotely as friendly as `mutate` in R. AQ subtle differencve in the read_csv command is that with Polars, it refuses to read 0 and 1 as Boolean, directly. Instead, this has been done with an explicit type cast, which performs multiple casts at once, using a dictionary. This is even more elegant than in R, where one would use mutate statements for typecasting.

```{python}
import polars as pl
from polars import read_csv, String, Int16, Float32, Boolean, col
import os

stim_dir = "Stimuli/"

schema_stim = { 'File': String,
                'width': Int16,
                'height': Int16,
                'hum_like': Float32,
                'hum_skull': Int16,
                'hum_eye': Int16,
                'Face': String}


stims = read_csv(stim_dir + "/Stimuli.csv", schema = schema_stim ).\
        cast({"hum_eye": Boolean, "hum_skull": Boolean}).\
        with_columns((stim_dir + col("File")).alias("Path"))


schema_aoi={'Face': String,
        'AOI': String,
        'x': Float32,
        'y': Float32,
        'w': Float32,
        'h': Float32}


aois = read_csv(stim_dir + "/AOI.csv", schema = schema_aoi)\
  .with_columns(((col.x).alias("xmin")),
                (col.x + col.w).alias("xmax"),
                (col.y - col.h).alias("ymin"),
                (col.y).alias("ymax"))\
  .rename({"x": "x_aoi",
           "y": "y_aoi",
           "w": "w_aoi",
           "h": "h_aoi"})
```



## Reading raw data

### Tidyverse

For reading the actual data files, we in R we first create a function to read and clean one data file. Then we use a higher level function `map_df`, which iterates over all csv files, opens them and stacks them into one file.

A bug in an early version of the eye tracker duplicated every measure. By using the `lag`` function, we filter for lines that do not match the previous line. Furthermore, participant identifiers are actually time stamps of the start of the session. These identifiers are shortened, by subtracting the the earliest time stamp 

```{r}
library(tidyverse)

yeta_types <- cols(Part = col_integer(), 
                            Picture = col_character(), 
                            time = col_double(), 
                            xraw = col_double(), yraw = col_double(), 
                            x = col_double(), y = col_double())

read_yeta1_csv <- function(file){
  read_csv(file, col_types = yeta_types) %>% 
    mutate(is_duplicate = x == lag(x) & y == lag(y)) %>% 
    filter(!is_duplicate) %>% 
    mutate(File = file, 
           Exp = "UV22") %>% 
    select(Exp, Part, Stim = Picture, time, x, y)
}

csv_files <- dir(path = "Data/",
             pattern = "*.csv",
             recursive = T,
             full.names = T)

D_0 <- 
    csv_files %>% 
    map_df(read_yeta1_csv) %>% 
    mutate(Exp = "UV22",
           Obs  = row_number()) %>%
    mutate(Part = Part - min(Part) + 1) %>% ## reducing the Part identifier
    group_by(Part) %>%
    mutate(time = time - min(time)) %>% # time since start experiment
    ungroup() |> 
    select(Exp, Obs, Part, Stim, time, x, y)

sample_n(D_0, 10) |> 
  arrange(Obs)
```
### Polars

In Polars deleting duplicate lines works similarly with the `shift` function, and with `drop` it is easy to remove one or multiple columns. Instead of a map function we use a `for` loop with a a method for vertical stacking. This requires that an initial data frame exists. This does not cause much overhead, as the data frame constructor accepts the type definition table, we have already defined for the csv files.

For creating a row-wise index for the observation identifier, Polars brings a shortcut function, which even places the index column in first position. In contrast, creating a new column with a constant value looks absurdly complicated.

```{python}
from polars import *
from glob import glob
import os

schema_csv={
        'Part': Int32,
        'Picture': String,
        'time': Float64,
        'x':    Float32,
        'y':    Float32,
        'xraw': Float32,
        'yraw': Float32
    }


def read_yeta1_csv(file):
  out = read_csv(file, schema = schema_csv)
  out = out.with_columns(shift_x = col("x").shift(), shift_y = col("y").shift())
  out = out.filter((out["x"]!=out["shift_x"]) & (out["y"]!=out["shift_y"]))
  out = out.drop(["shift_x", "shift_y"])
  return out


csv_dir = os.path.join(os.path.curdir, "Data")
csv_files = glob(csv_dir + "/*.csv")    

D_0 = DataFrame(schema = schema_csv)
for f in csv_files:
  D_0 = D_0.vstack(read_yeta1_csv(f))

D_0 = D_0.rename({"Picture": "Stim"})
D_0 = D_0.with_row_index(name = "Obs", offset = 1) ## new index column
D_0 = D_0.with_columns(pl.lit("UV22").alias("Exp")) ## new col with constant value
D_0 = D_0.with_columns(Part = (col("Part") - col("Part").min() + 1))
D_0 = D_0.with_columns(time = (col("time") - col("time").min()).over("Part"))
D_0 = D_0.with_columns(col("Part").cast(String))
D_0 = D_0.select(["Exp", "Obs", "Part", "Stim", "time", "x", "y"])

D_0

```


## Joining tables


### Tidyverse

In this step, we are merging the observation with the meta data on stimuli and aoi.
Note that with the right join, the data set gets expanded by the AOI factor. The subsequent filter command reduces the data set to only observations that fell into one AOI. In tidy R, this is a breeze.


```{r}
D_1 <- 
  D_0 |> 
  left_join(stims, by = "Stim") |> 
  right_join(aoi, by = "Face") |> 
  mutate(is_in_aoi = x > xmin & x < xmax & y > ymin & y < ymax) |> 
  filter(is_in_aoi) |> 
  select(Obs, Exp, Part, Stim, time, x, y, AOI)
  
```



### Polars

In Polars a single join function fulfills all possible joins. Besides that, it is easy to specify even un-matching key variables.
When calculating new columns, it is important to use the expressions that Polars brings. Here, we have to use `lt` (less than) and `gt` (greater than), instead of the native Python operators. The catalogue of function that Polars leaves nothing to be desired.


```{python}
from polars import *
from glob import glob
import os

D_1 = D_0.join(stims, left_on = "Stim", right_on = "File", how = "left")
D_1 = D_1.join(aois, on = "Face", how = "right", suffix = "_aoi")

D_1 = D_1.with_columns((col.x.gt(col.xmin) & col.x.lt(col.xmax) &  col.y.gt(col.ymin) & col.y.lt(col.ymax)).alias("is_in"))
D_1 = D_1.filter(col.is_in)
                

```


## Deriving measures

At this point, we have left all eye positions that wer on AOIs. Frokm this, we can derive further measures:

+ the travel distance to the last observed coordinates are derived using Euclidiab distance
+ The total dwelling time per area is derived per stimulus and participant.
+ episodes are used to reduce the data. An episode is defined by an AOI, and two time stamps for entering and leaving the area. If the particiant taxes the eyes for two seconds, these two seconds become one row of data. 
+ episodes are used to derive *restlessness* as the frequency of hopping to another area

### Tidyverse

```{r}
D_2 <- 
  D_1 |> 
  mutate(data,  travel = sqrt(sq(x - lag(x) + sq(y - lag(y)))) |> 
  
  

add_travel   <- function(data) mutate(data,  travel = sqrt((x - lag(x))^2 + (y - lag(y))^2))
add_duration <- function(data) mutate(data,  duration = lead(time) - time)


|> 
  add_travel() |> 
  add_duration() |> 

  filter(is_in_aoi) |> 
  select(Obs, Part, Stim, Face, time, x, y, AOI, hum_like, hum_skull, hum_eye, duration, travel)




```



## Raw data visualization

```{r}
get_last_part <- function(data){
  last_part <- 
    distinct(data, Part) %>% 
    filter(as.numeric(Part) == max(as.numeric(Part), na.rm = T)) %>% 
    left_join(data, by = "Part")
  return(last_part)
}

```

```{r}
G_0 +
  geom_point(aes(x = x, y = y),
             size = 2,
             col = "red",
             alpha = .2,
             data = get_last_part(D_0),
             inherit.aes = F) +
  facet_wrap(~Stim)
```

```{r}
G_0 +
  geom_point(aes(x = x, y = y,
                 col = Part), # <--
             size = 2,
             data = D_0, # <--
             inherit.aes = F) +
  facet_wrap(~Stim)
```

```{r}
G_0 +
  geom_point(aes(x = x, y = y,
                 col = Part),
             data = get_last_part(D_0),
             size = .1,
             inherit.aes = F) +
  geom_line(aes(x = x , 
                y = y,
                group = Part),
                col = "red",
             inherit.aes = F,
            data = get_last_part(D_0)) +
  facet_wrap(~Stim)
```

### Adding Stimulus meta data

```{r}
D_1 <- 
  D_0 %>% 
  left_join(Stimuli, by = "Stim") %>% 
  select(Obs, Part, Stim, Face, hum_like, Sclera, Skull, time, x, y)

sample_n(D_1, 12)
```

## Deriving measures

-   measuring travel and duration

```{r}
add_travel <- 
  function(data) 
    mutate(data,  travel = sqrt((x - lag(x))^2 + (y - lag(y))^2))

add_duration <- 
  function(data) 
    mutate(data,  duration = lead(time) - time)


D_2 <- 
  D_1 %>% 
  mutate(Sequence = as.factor(str_c(Part, Stim, sep = "_"))) %>% 
  group_by(Sequence) %>% 
  add_duration() %>% 
  add_travel() %>% 
  ungroup() %>% 
  select(Obs, Part, Stim, Face, Sequence, hum_like, 
         Sclera, Skull, time, x, y, travel, duration)
```

```{r}

D_2 %>% 
  ggplot(aes(x = duration)) +
  geom_histogram() +
  facet_wrap(~Stim)


D_2 %>% 
  ggplot(aes(x = travel)) +
  geom_histogram() +
  facet_wrap(~Stim)
```

### Areas of interest

#### Reading AOI

```{r}
read_yeta1_aoi <- 
  function(file = "Stimuli/AOI.csv",
           stim_dir = "Stimuli/",
           col_types = cols(AOI = col_character(), Face = col_character(), 
                            x = col_double(), y = col_double(), 
                            w = col_double(), h = col_double()),
           stim_tab) {
    
    read_csv(file, col_types = col_types) %>% 
      rename(x_aoi = x, y_aoi = y, w_aoi = w, h_aoi = h) %>% 
      right_join(stim_tab, by = "Face") %>% 
      mutate(xmin = x_aoi, 
             xmax = x_aoi + w_aoi,
             ymax = height - y_aoi, ## reversing the y coordinates
             ymin = (height - y_aoi) - h_aoi) %>% 
      arrange(Face, AOI)
  }

```

```{r}
AOI <- read_yeta1_aoi(stim_tab = Stimuli)

head(AOI)
```

#### AOI preview

```{r fig.height = 8, fig.width = 8}
G_1 <- 
  AOI %>% 
  ggplot(aes(xmin = 0, xmax = width, 
             ymin = 0, ymax = height)) +
  facet_wrap(~Face) + # <--
  ggimg::geom_rect_img(aes(img = Path)) +
  geom_rect(aes(xmin = xmin, ymin = ymin, 
                xmax = xmax, ymax = ymax,
                fill = AOI),
            alpha = .2, 
            inherit.aes  = F)

G_1
```

#### AOI Classification

```{r}
D_3 <- 
  D_2 %>% 
  left_join(AOI, by = "Face") %>% 
  mutate(is_in = x > xmin & x < xmax & y > ymin & y < ymax) %>% 
  filter(is_in) %>% 
  select(Obs, AOI) %>% 
  right_join(D_2, by = "Obs") %>% 
  mutate(AOI = if_else(is.na(AOI), "Outside", AOI)) %>% 
  arrange(Part, time)

summary(D_3)
```

```{r}
D_3 %>% 
  group_by(AOI, Sclera, Skull) %>% 
  summarize(n = n()) %>% 
  ungroup() %>% 
  ggplot(aes(y = n, x = AOI, fill = AOI)) +
  facet_grid(Skull~Sclera) +
  geom_col()

```

```{r}
G_0 +
  geom_count(aes(x = x, y = y, 
                 col = AOI),
             alpha = .5,
             inherit.aes  = F,
             data = D_3)
```

### Measuring visits

A *visit* is a closed sequence of eye positions in the same region. The following code uses a combined criterion for setting a new visits:

-   the position falls into a different AOI

-   OR: the travel traveled from the previous position exceeds a certain threshold

```{r}

travel_threshold <- 50

D_4 <-

  D_3 %>%

  group_by(Part, Stim) %>%

  filter(AOI != lag(AOI) | travel > travel_threshold) %>% ## logical OR

  mutate(visit = row_number(),

         duration = lead(time) - time) %>%

  ungroup()

sample_n(D_4, 10)

```

#### Plotting visit paths and duration

```{r fig.width=8, fig.height = 8}

G_3 <-

  G_0 +
  geom_point(aes(x = x, y = y,
                 size = duration), # <--
             color = "white",
             alpha = .2,
             inherit.aes  = F,
             data = D_4)

G_3

```

```{r}

G_4 <-
  G_0 +
  geom_path(aes(x = x, y = y,
                col = Part),
            inherit.aes  = F,
            data = D_4) # <--

G_4

```


## Participant-level analysis

### Frequencies and durations

```{r}

D_6 <-
  D_4 %>%
  group_by(Part, Face, AOI, Sclera, Skull) %>%  # <--
  summarize(n_visits = n(),
            total_dur = sum(duration, na.rm = TRUE)) %>%
  ungroup() %>% 
  mutate(congruent = (Sclera == Skull))


D_6

```

```{r}

G_6 <-

  D_6 %>%
  ggplot(aes(x = congruent, y = n_visits, fill = AOI)) +
  facet_wrap(~Part) +
  geom_col()

G_6

```


```{r}

G_7 <-
  D_6 %>%
  ggplot(aes(x = AOI, y = total_dur, fill = congruent)) +
  facet_wrap(~Part) +
  geom_col()

G_7

```

```{r}

save(AOI, D_1, D_2, D_3, D_4, D_6, file = "D.Rda")

```

